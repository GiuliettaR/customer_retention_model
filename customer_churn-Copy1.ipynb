{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Customer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = pd.read_csv('data/MFG-customers.csv')\n",
    "customers = customers.loc[:, ['CustomerID', 'City', 'State', 'Country']]\n",
    "customers['Location'] = customers['State'].fillna(customers['Country']).apply(lambda x: str(x).upper())\n",
    "customers['City'] = customers['City'].apply(lambda x: str(x).upper())\n",
    "customers.drop(columns=['State', 'Country'], inplace=True)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Accounts Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts = pd.read_csv('data/MFG-accounts.csv', usecols=['Account_ID', 'Revenue_Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Invoices Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices = pd.read_csv('data/MFG-invoices.csv', parse_dates=True)\n",
    "invoices['Date'] = invoices['Date'].apply(pd.Timestamp)\n",
    "invoices['Month'] = invoices['Date'].apply(lambda x: x.month)\n",
    "invoices['Year'] = invoices['Date'].apply(lambda x: x.year)\n",
    "invoices['Day'] = invoices['Date'].apply(lambda x: x.day) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices ['Amount'] = (invoices['Amount'].str.replace(',', '').astype(float)).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices['Unit_Price'] = invoices['Unit_Price'].apply(\n",
    "    lambda x: x.replace(',', '') if isinstance(x, str) else x\n",
    ")\n",
    "invoices['Amount'] = invoices['Amount'].apply(\n",
    "    lambda x: x.replace(',', '') if isinstance(x, str) else x\n",
    ")\n",
    "invoices['Qty'] = invoices['Qty'].apply(\n",
    "    lambda x: x.replace(',', '') if isinstance(x, str) else x\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Qty</th>\n",
       "      <th>Unit_Price</th>\n",
       "      <th>Item_ID</th>\n",
       "      <th>Account_ID</th>\n",
       "      <th>Amount</th>\n",
       "      <th>CustID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1695.00</td>\n",
       "      <td>RP-SLA-1</td>\n",
       "      <td>200-4040</td>\n",
       "      <td>1695.00</td>\n",
       "      <td>686006</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>66.91</td>\n",
       "      <td>SHP-MFG</td>\n",
       "      <td>200-4210</td>\n",
       "      <td>66.91</td>\n",
       "      <td>686006</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>1</td>\n",
       "      <td>23080.00</td>\n",
       "      <td>RP-INJMOLD-1</td>\n",
       "      <td>200-4041</td>\n",
       "      <td>23080.00</td>\n",
       "      <td>487033</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>1</td>\n",
       "      <td>3850.00</td>\n",
       "      <td>RP-INJMOLD-1</td>\n",
       "      <td>200-4041</td>\n",
       "      <td>3850.00</td>\n",
       "      <td>487033</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>1</td>\n",
       "      <td>7830.15</td>\n",
       "      <td>RP-INJMOLD-1</td>\n",
       "      <td>200-4041</td>\n",
       "      <td>7830.15</td>\n",
       "      <td>487033</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Qty Unit_Price       Item_ID Account_ID    Amount  CustID  Month  \\\n",
       "0 2015-07-01   1    1695.00      RP-SLA-1   200-4040   1695.00  686006      7   \n",
       "1 2015-07-01   1      66.91       SHP-MFG   200-4210     66.91  686006      7   \n",
       "2 2015-07-02   1   23080.00  RP-INJMOLD-1   200-4041  23080.00  487033      7   \n",
       "3 2015-07-02   1    3850.00  RP-INJMOLD-1   200-4041   3850.00  487033      7   \n",
       "4 2015-07-02   1    7830.15  RP-INJMOLD-1   200-4041   7830.15  487033      7   \n",
       "\n",
       "   Year  Day  \n",
       "0  2015    1  \n",
       "1  2015    1  \n",
       "2  2015    2  \n",
       "3  2015    2  \n",
       "4  2015    2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Industry + Press Release Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry = pd.read_csv('data/MFG-industry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "press_release = pd.read_csv('data/Press_Release.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "press_release['Release Date'] = press_release['Release Date'].apply(pd.Timestamp)\n",
    "press_release['Month'] = press_release['Release Date'].apply(lambda x: x.month)\n",
    "press_release['Year'] = press_release['Release Date'].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#press_release = press_release.drop(columns=['PR ID', 'Status', 'Last Modified'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "press_release=press_release[['Headline', 'Column1', 'Premium', 'Hits', 'Release Date','Month','Year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = 90\n",
    "min_diff_days = 3\n",
    "repeat=[]\n",
    "for invoice in invoices.iterrows():\n",
    "    repeat.append((\n",
    "        (invoice[1]['CustID'] == invoices['CustID']) \n",
    "        & (invoice[1]['Date'] < invoices['Date']) \n",
    "        & (invoices['Date'] - invoice[1]['Date'] < pd.Timedelta(n_days, 'd'))\n",
    "        & (invoices['Date'] - invoice[1]['Date'] > pd.Timedelta(min_diff_days, 'd'))\n",
    "    ).any())  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_invoice_date = invoices.groupby('CustID')['Date'].min()\n",
    "# customers['First_Invoice'] = first_invoice_date[customers['CustomerID']].values\n",
    "\n",
    "# days_since_last = invoices.groupby('CustID').apply(lambda x: np.diff(pd.Series.sort_values(x['Date']).values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cust = invoices.groupby('CustID')['Amount'].agg('cumsum')\n",
    "mean_cust = invoices.groupby('CustID')['Amount'].agg('mean')\n",
    "\n",
    "#here I used a merge db\n",
    "total_rev_class = X.groupby('Revenue_Class')['Amount'].agg('sum')\n",
    "mean_rev_class = X.groupby('Revenue_Class')['Amount'].agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices['Customer_Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.groupby.SeriesGroupBy object at 0x1b826118d0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.groupby('Revenue_Class')['CustID']\n",
    "X.groupby('Item_ID')['CustID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Column1</th>\n",
       "      <th>Premium</th>\n",
       "      <th>Hits</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Padt Adds Ansys Fluent Udf Services And Ansys ...</td>\n",
       "      <td>Simulation</td>\n",
       "      <td>-</td>\n",
       "      <td>2716</td>\n",
       "      <td>2010-02-04</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PADT Celebrates Grand Opening of Colorado Offi...</td>\n",
       "      <td>Expansion</td>\n",
       "      <td>-</td>\n",
       "      <td>1987</td>\n",
       "      <td>2010-10-13</td>\n",
       "      <td>10</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PADT, Inc. Wins 2011 W P Carey Spirit of Enter...</td>\n",
       "      <td>Award</td>\n",
       "      <td>-</td>\n",
       "      <td>984</td>\n",
       "      <td>2011-11-10</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PADT, Inc. Wins 2011 Governor’s Celebration of...</td>\n",
       "      <td>Award</td>\n",
       "      <td>-</td>\n",
       "      <td>1968</td>\n",
       "      <td>2011-11-21</td>\n",
       "      <td>11</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PADT Adds Flownex Thermal-Fluid System Simulat...</td>\n",
       "      <td>Simulation</td>\n",
       "      <td>-</td>\n",
       "      <td>1390</td>\n",
       "      <td>2012-01-18</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PADT Increases Prototyping Capacity with Addit...</td>\n",
       "      <td>3D Printing</td>\n",
       "      <td>-</td>\n",
       "      <td>1682</td>\n",
       "      <td>2012-02-01</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PADT Starts \"3D Printing on Every Desktop\" Eff...</td>\n",
       "      <td>3D Printing</td>\n",
       "      <td>-</td>\n",
       "      <td>1607</td>\n",
       "      <td>2012-03-06</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PADT Adds 3D Scanners and Scanning Services</td>\n",
       "      <td>Scanning</td>\n",
       "      <td>-</td>\n",
       "      <td>5181</td>\n",
       "      <td>2012-04-17</td>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business and Clean Energy Goals Align with Ins...</td>\n",
       "      <td>Design</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4260</td>\n",
       "      <td>2012-09-06</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PADT, Inc. To Distribute VCollab CAE Collabora...</td>\n",
       "      <td>Simulation</td>\n",
       "      <td>-</td>\n",
       "      <td>3853</td>\n",
       "      <td>2012-09-13</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PADT Adds Objet Line of Polyjet 3D Printers to...</td>\n",
       "      <td>3D Printing</td>\n",
       "      <td>-</td>\n",
       "      <td>2685</td>\n",
       "      <td>2013-03-04</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PADT Expands Local 3D Printing, Support, and S...</td>\n",
       "      <td>3D Printing</td>\n",
       "      <td>-</td>\n",
       "      <td>2475</td>\n",
       "      <td>2013-06-17</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PADT Achieves ISO 13485:2003 Certification for...</td>\n",
       "      <td>Design</td>\n",
       "      <td>-</td>\n",
       "      <td>1396</td>\n",
       "      <td>2013-06-20</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Free Thermal-Fluid Simulation Training Offered...</td>\n",
       "      <td>Simulation</td>\n",
       "      <td>-</td>\n",
       "      <td>985</td>\n",
       "      <td>2014-03-05</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fluid-Thermal System Modeling for Mining with ...</td>\n",
       "      <td>Simulation</td>\n",
       "      <td>-</td>\n",
       "      <td>856</td>\n",
       "      <td>2014-03-05</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PADT, Provider of Engineering Services and Pro...</td>\n",
       "      <td>General</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1854</td>\n",
       "      <td>2014-03-06</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PADT to Present 3D Printing at Digital Printin...</td>\n",
       "      <td>3D Printing</td>\n",
       "      <td>-</td>\n",
       "      <td>1731</td>\n",
       "      <td>2014-04-04</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Flownex 2014 Released and Webinars Announced</td>\n",
       "      <td>Simulation</td>\n",
       "      <td>-</td>\n",
       "      <td>967</td>\n",
       "      <td>2014-07-18</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Utah PADT Office Opened to Enhance Local 3D Pr...</td>\n",
       "      <td>Expansion</td>\n",
       "      <td>-</td>\n",
       "      <td>2170</td>\n",
       "      <td>2014-09-09</td>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Congratulations to the Winners of PADT’s FIRST...</td>\n",
       "      <td>STEM</td>\n",
       "      <td>-</td>\n",
       "      <td>2123</td>\n",
       "      <td>2014-10-30</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline      Column1 Premium  \\\n",
       "0   Padt Adds Ansys Fluent Udf Services And Ansys ...   Simulation       -   \n",
       "1   PADT Celebrates Grand Opening of Colorado Offi...    Expansion       -   \n",
       "2   PADT, Inc. Wins 2011 W P Carey Spirit of Enter...        Award       -   \n",
       "3   PADT, Inc. Wins 2011 Governor’s Celebration of...        Award       -   \n",
       "4   PADT Adds Flownex Thermal-Fluid System Simulat...   Simulation       -   \n",
       "5   PADT Increases Prototyping Capacity with Addit...  3D Printing       -   \n",
       "6   PADT Starts \"3D Printing on Every Desktop\" Eff...  3D Printing       -   \n",
       "7         PADT Adds 3D Scanners and Scanning Services     Scanning       -   \n",
       "8   Business and Clean Energy Goals Align with Ins...       Design     NaN   \n",
       "9   PADT, Inc. To Distribute VCollab CAE Collabora...   Simulation       -   \n",
       "10  PADT Adds Objet Line of Polyjet 3D Printers to...  3D Printing       -   \n",
       "11  PADT Expands Local 3D Printing, Support, and S...  3D Printing       -   \n",
       "12  PADT Achieves ISO 13485:2003 Certification for...       Design       -   \n",
       "13  Free Thermal-Fluid Simulation Training Offered...   Simulation       -   \n",
       "14  Fluid-Thermal System Modeling for Mining with ...   Simulation       -   \n",
       "15  PADT, Provider of Engineering Services and Pro...      General     NaN   \n",
       "16  PADT to Present 3D Printing at Digital Printin...  3D Printing       -   \n",
       "17       Flownex 2014 Released and Webinars Announced   Simulation       -   \n",
       "18  Utah PADT Office Opened to Enhance Local 3D Pr...    Expansion       -   \n",
       "19  Congratulations to the Winners of PADT’s FIRST...         STEM       -   \n",
       "\n",
       "    Hits Release Date  Month  Year  \n",
       "0   2716   2010-02-04      2  2010  \n",
       "1   1987   2010-10-13     10  2010  \n",
       "2    984   2011-11-10     11  2011  \n",
       "3   1968   2011-11-21     11  2011  \n",
       "4   1390   2012-01-18      1  2012  \n",
       "5   1682   2012-02-01      2  2012  \n",
       "6   1607   2012-03-06      3  2012  \n",
       "7   5181   2012-04-17      4  2012  \n",
       "8   4260   2012-09-06      9  2012  \n",
       "9   3853   2012-09-13      9  2012  \n",
       "10  2685   2013-03-04      3  2013  \n",
       "11  2475   2013-06-17      6  2013  \n",
       "12  1396   2013-06-20      6  2013  \n",
       "13   985   2014-03-05      3  2014  \n",
       "14   856   2014-03-05      3  2014  \n",
       "15  1854   2014-03-06      3  2014  \n",
       "16  1731   2014-04-04      4  2014  \n",
       "17   967   2014-07-18      7  2014  \n",
       "18  2170   2014-09-09      9  2014  \n",
       "19  2123   2014-10-30     10  2014  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "press_release.sort_values(['Year', 'Month']).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = invoices.merge(customers, how='left', left_on=['CustID'], right_on=['CustomerID'])\n",
    "X = X.merge(accounts, how='left', on=['Account_ID'])\n",
    "X = X.merge(industry, how='left', left_on=['CustID'],right_on=['CustID'])\n",
    "#X = X.merge(press_release, how='left', left_on=['Year','Month'], right_on=['Year','Month'])\n",
    "# X.drop(columns=['CustID', 'CustomerID'], inplace=True)\n",
    "y = pd.Series(repeat, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['ttl_amount_cust'] = total_cust#total_cust.loc[X['CustID'].values].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = X['Date'].max() - pd.Timedelta(n_days, 'd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have enough data after this date, we can't include it in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[X['Date'] < cutoff_date]\n",
    "X = X[X['Date'] < cutoff_date]\n",
    "\n",
    "X.drop(columns=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12396,), (12396, 12))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nan(X, y):\n",
    "    X['Item_ID'] = X['Item_ID'].astype(str)\n",
    "    X['Revenue_Class'] = X['Revenue_Class'].astype(str)\n",
    "    y = y[~X.isna().any(axis=1)]\n",
    "    X.dropna(inplace=True)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder():\n",
    "    def __init__(self, columns):\n",
    "        self.encoder = None \n",
    "        self.col_names = None\n",
    "        self.columns = columns\n",
    "        self.values = []\n",
    "    \n",
    "    def fit(self, X):\n",
    "        X = X.loc[:, self.columns].astype(str)\n",
    "        self.values = [np.unique(X[col]) for col in X] \n",
    "        self.encoder = OneHotEncoder(categories=self.values, handle_unknown='ignore')\n",
    "        \n",
    "        self.encoder.fit(X)\n",
    "        col_names = []\n",
    "        for column, values in zip(self.columns, self.values):\n",
    "            for value in values:\n",
    "                \n",
    "                col_names.append(f'{column}_{value}') \n",
    "        self.col_names = col_names \n",
    "    def transform(self, X):\n",
    "        ar = self.encoder.transform(X.loc[:, self.columns].astype(str))\n",
    "        ar = ar.todense()\n",
    "        X = X.drop(columns=self.columns)\n",
    "        for i, col in enumerate(self.col_names):\n",
    "            X[col] = ar[:, i]\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Item_ID', 'Month', 'Year', \n",
    "                        'Location', 'Revenue_Class',\n",
    "                        'City', 'Item_ID', 'Account_ID', 'Industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lulu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/lulu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/lulu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = clean_nan(X_train, y_train)\n",
    "X_test, y_test = clean_nan(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = encoder.transform(X_train)\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(1000)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2162425295280967"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, rf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1500, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(1500)\n",
    "rf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2161732522426927"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, rf2.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf3 = RandomForestClassifier(2000)\n",
    "rf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21681106285021595"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, rf3.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2500, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf4 = RandomForestClassifier(2500)\n",
    "rf4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21661128861787673"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, rf4.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2700, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf5 = RandomForestClassifier(2700)\n",
    "rf5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2159264854049905"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, rf5.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=3000, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf6 = RandomForestClassifier(3000)\n",
    "rf6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21576275042190166"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, rf6.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=3500, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf7 = RandomForestClassifier(3500)\n",
    "rf7.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2160654357390641"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, rf7.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=2700, max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.28699466, -0.25013999, -0.28448425])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(gb, X_train, y_train, cv=3, scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=4,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=2700,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20363756859111456"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, gb.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb1= GradientBoostingClassifier(n_estimators=3500, max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.30085709, -0.26725782, -0.30424836])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(gb1, X_train, y_train, cv=3, scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=4,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=3500,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20337560693703252"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, gb1.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2794"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin([log_loss(y_test, y_pred) for y_pred in gb1.staged_predict_proba(X_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(solver='liblinear')\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3757392072058761"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, log_reg.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = log_reg.predict(X_train)\n",
    "test_predictions = log_reg.predict_proba(X_test)\n",
    "train_probas = log_reg.predict_proba(X_train)\n",
    "test_probas = log_reg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probas = log_reg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probabilities</th>\n",
       "      <th>predictions</th>\n",
       "      <th>actuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.537141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.851127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.939730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.979622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   probabilities  predictions  actuals\n",
       "0       0.537141          1.0      0.0\n",
       "1       0.950985          1.0      1.0\n",
       "2       0.851127          1.0      1.0\n",
       "3       0.939730          1.0      1.0\n",
       "4       0.979622          1.0      1.0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "model_results = pd.DataFrame(np.column_stack((test_probas,\n",
    "                                              test_probas >= threshold,\n",
    "                                              y_test)))\n",
    "model_results.columns = ['probabilities','predictions','actuals']\n",
    "model_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3757392072058761"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_pred = model_results['probabilities'].values, y_true = model_results['actuals'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roc Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b407999b0>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "fpr, tpr, threshold = roc_curve(y_train, gb.predict_proba(X_train)[:, 1])\n",
    "plt.plot(fpr, tpr, label='train')\n",
    "fpr, tpr, threshold = roc_curve(y_test, gb.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr, tpr, label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8315442698952082"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(model_results.actuals.values, model_results.probabilities.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profic Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results['category'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probabilities</th>\n",
       "      <th>predictions</th>\n",
       "      <th>actuals</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.537141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.851127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.939730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.979622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   probabilities  predictions  actuals category\n",
       "0       0.537141          1.0      0.0       FP\n",
       "1       0.950985          1.0      1.0       TP\n",
       "2       0.851127          1.0      1.0       TP\n",
       "3       0.939730          1.0      1.0       TP\n",
       "4       0.979622          1.0      1.0       TP"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results.loc[(model_results.predictions == True) & (model_results.actuals == True),'category'] = 'TP'\n",
    "model_results.loc[(model_results.predictions == True) & (model_results.actuals == False),'category'] = 'FP'\n",
    "model_results.loc[(model_results.predictions == False) & (model_results.actuals == False),'category'] = 'TN'\n",
    "model_results.loc[(model_results.predictions == False) & (model_results.actuals == True),'category'] = 'FN'\n",
    "model_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>2368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category\n",
       "TP      2368\n",
       "FP       413\n",
       "TN       216\n",
       "FN        99"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_results.category.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso_regularization_strengths = np.logspace(np.log10(0.00001), np.log10(10), num=100)\n",
    "\n",
    "#lasso_regressions = []\n",
    "#for alpha in lasso_regularization_strengths:\n",
    "#    lasso = Lasso(alpha=alpha)\n",
    "#    lasso.fit(X_train, y_train)\n",
    "#    lasso_regressions.append(lasso)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def plot_solution_paths(ax, regressions, columns):\n",
    "#    alphas = [np.log10(ridge.alpha) for ridge in regressions]\n",
    "#    coeffs = np.concatenate([ridge.coef_.reshape(1, -1) \n",
    "#                             for ridge in regressions])\n",
    "#    for i,idx in enumerate(range(coeffs.shape[1])):\n",
    "#        name = columns[i]\n",
    "#        ax.plot(alphas, coeffs[:, idx], label = name)\n",
    "#    ax.set_xlabel(r\"$\\log_{10}(\\alpha)$\")\n",
    "#    ax.set_ylabel(\"Estiamted Coefficient\")\n",
    "#    ax.set_title(\"Coefficient Paths\")\n",
    "#    ax.legend(loc = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = list(X_train.columns)\n",
    "#fig, ax = plt.subplots(figsize=(16, 6))\n",
    "#plot_solution_paths(ax, lasso_regressions, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Feature Importance\n",
    "#coefs = []\n",
    "#for reg in lasso_regressions:\n",
    "#    coefs.append(reg.coef_)\n",
    "#coefs = pd.DataFrame(coefs)\n",
    "#coefs.columns = list(X_train.columns)\n",
    "#np.sum(np.round(np.abs(coefs),3) > 0,axis = 0).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
